{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba con DeepSORT Realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getColor(class_name):\n",
    "    switch = {\n",
    "        'player': (255, 0, 0),       # Azul\n",
    "        'basketball': (0, 165, 255), # Naranja\n",
    "        'rim': (0, 0, 255),          # Rojo\n",
    "        'made-shot': (0, 255, 0)     # Verde\n",
    "    }\n",
    "    return switch.get(class_name, (0, 0, 0)) \n",
    "\n",
    "def drawBBox(frame, x1, y1, x2, y2, label, class_name):\n",
    "    color = getColor(class_name)\n",
    "    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "    cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "def drawPosition(frame, position, position_label):\n",
    "    cv2.ellipse(frame, (int(position[0]), int(position[1])), (9, 3), 0, 0, 360, (0, 0, 255), -1)\n",
    "    cv2.putText(frame, position_label, (int(position[0]) - 50, int(position[1]) + 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "\n",
    "object_detector = YOLO(\"../object_detection/runs/detect/bod_v1/weights/best.pt\")\n",
    "\n",
    "tracker = DeepSort(max_age=50, n_init=5, nms_max_overlap=1.0)\n",
    "\n",
    "video_path = \"../clips/ClipLF1.mp4\"\n",
    "output_path = \"../output/ClipLF1_tracking_output.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"avc1\")\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "MAX_PLAYERS = 10\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    object_detection_results = object_detector(frame)\n",
    "\n",
    "    detections = []\n",
    "    # An치lisis de las detecciones de jugadores\n",
    "    for result in object_detection_results[0].boxes.data.tolist():  # Obtener los resultados como lista\n",
    "        x1, y1, x2, y2, conf, cls = result  # Coordenadas, confianza y clase\n",
    "        cls = int(cls)\n",
    "\n",
    "        # Filtrar solo por las clases deseadas\n",
    "        if object_detector.names[cls] in ['player'] and conf > 0.5:\n",
    "            detections.append(([x1, y1, x2-x1, y2-y1], conf, cls))\n",
    "\n",
    "    tracking_results = tracker.update_tracks(detections, frame=frame)\n",
    "\n",
    "    # Filtrar solo los tracks confirmados\n",
    "    confirmed_tracks = [track for track in tracking_results if track.is_confirmed()]\n",
    "\n",
    "    # Ordenar por track_id (IDs m치s bajos primero) y mantener solo 10\n",
    "    if len(confirmed_tracks) > MAX_PLAYERS:\n",
    "        confirmed_tracks = sorted(confirmed_tracks, key=lambda t: t.track_id)[:MAX_PLAYERS]\n",
    "\n",
    "    for track in confirmed_tracks:\n",
    "        track_id = track.track_id  # Obtener el ID del track\n",
    "        x1, y1, x2, y2 = track.to_ltrb()  # Bounding box en formato [left, top, right, bottom]\n",
    "        drawBBox(frame, x1, y1, x2, y2, f\"ID: {track_id}\", 'player')\n",
    "\n",
    "        position = (int((x1 + x2) / 2), y2)\n",
    "        position_label = f\"x:{int(position[0])} y:{int(position[1])}\"\n",
    "        drawPosition(frame, position, position_label)\n",
    "\n",
    "\n",
    "\n",
    "    # Mostrar el frame procesado en pantalla\n",
    "    cv2.imshow('Resultados', frame)\n",
    "\n",
    "    # Esperar por una tecla: espacio para avanzar, 'q' para salir\n",
    "    key = cv2.waitKey(0) & 0xFF  # Espera indefinidamente hasta que se presione una tecla\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord(' '):  # Espacio para continuar\n",
    "        # Escribir el frame procesado en el video de salida\n",
    "        out.write(frame)\n",
    "\n",
    "\n",
    "# Liberar recursos\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Video procesado guardado en {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracking V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "\n",
    "object_detector = YOLO(\"../object_detection/runs/detect/bod_v1/weights/best.pt\")\n",
    "\n",
    "tracker = DeepSort(max_age=50, n_init=5, nms_max_overlap=1.0)\n",
    "\n",
    "video_path = \"../clips/ClipS1.mp4\"\n",
    "output_path = \"../output/ClipS1_tracking_output.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"avc1\")\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "MAX_PLAYERS = 10\n",
    "\n",
    "MAX_FRAMES_WITHOUT_DETECTION = 3\n",
    "\n",
    "# Diccionario para mapear track_id originales a IDs fijos (1-10)\n",
    "id_mapping = {}\n",
    "lost_ids = set(range(1, MAX_PLAYERS + 1))  # IDs disponibles (1-10)\n",
    "active_ids = set()  # IDs actualmente asignados\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    object_detection_results = object_detector(frame)\n",
    "\n",
    "    detections = []\n",
    "    # An치lisis de las detecciones de jugadores\n",
    "    for result in object_detection_results[0].boxes.data.tolist():  # Obtener los resultados como lista\n",
    "        x1, y1, x2, y2, conf, cls = result  # Coordenadas, confianza y clase\n",
    "        cls = int(cls)\n",
    "\n",
    "        # Filtrar solo por las clases deseadas\n",
    "        if object_detector.names[cls] in ['player'] and conf > 0.5:\n",
    "            detections.append(([x1, y1, x2 - x1, y2 - y1], conf, cls))\n",
    "\n",
    "    tracking_results = tracker.update_tracks(detections, frame=frame)\n",
    "\n",
    "    # Filtrar solo los tracks confirmados\n",
    "    confirmed_tracks = [track for track in tracking_results \n",
    "                        if track.is_confirmed()\n",
    "                        and track.time_since_update <= MAX_FRAMES_WITHOUT_DETECTION]\n",
    "\n",
    "    for track in confirmed_tracks:\n",
    "        original_id = track.track_id  # ID asignado por DeepSORT\n",
    "\n",
    "        if original_id in id_mapping:\n",
    "            fixed_id = id_mapping[original_id]  # Usar el ID ya asignado\n",
    "        elif lost_ids:\n",
    "            fixed_id = lost_ids.pop()  # Tomar un ID libre\n",
    "            id_mapping[original_id] = fixed_id  # Asignarlo al nuevo jugador\n",
    "            active_ids.add(fixed_id)  # Registrar el ID como activo\n",
    "        else:\n",
    "            continue  # Si no hay IDs disponibles, ignoramos la detecci칩n\n",
    "\n",
    "        x1, y1, x2, y2 = track.to_ltrb()  # Bounding box en formato [left, top, right, bottom]\n",
    "        drawBBox(frame, x1, y1, x2, y2, f\"ID: {fixed_id}\", 'player')\n",
    "\n",
    "        position = (int((x1 + x2) / 2), y2)\n",
    "        position_label = f\"x:{int(position[0])} y:{int(position[1])}\"\n",
    "        drawPosition(frame, position, position_label)\n",
    "\n",
    "    # Identificar jugadores que han desaparecido\n",
    "    active_now = {id_mapping[track.track_id] for track in confirmed_tracks if track.track_id in id_mapping}\n",
    "    lost_ids.update(active_ids - active_now)  # Recuperar IDs de jugadores perdidos\n",
    "    active_ids = active_now  # Actualizar IDs activos\n",
    "\n",
    "    # Mostrar el frame procesado en pantalla\n",
    "    cv2.imshow('Resultados', frame)\n",
    "\n",
    "    # Esperar por una tecla: espacio para avanzar, 'q' para salir\n",
    "    key = cv2.waitKey(0) & 0xFF  # Espera indefinidamente hasta que se presione una tecla\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord(' '):  # Espacio para continuar\n",
    "        # Escribir el frame procesado en el video de salida\n",
    "        out.write(frame)\n",
    "\n",
    "\n",
    "# Liberar recursos\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Video procesado guardado en {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tftv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
