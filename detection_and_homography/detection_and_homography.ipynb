{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Librerías, paquetes y funciones importadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from skimage import transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawBBox(frame, x1, y1, x2, y2, label):\n",
    "    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n",
    "    cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (100, 200, 100), 2)\n",
    "\n",
    "def drawPosition(frame, position, position_label):\n",
    "    cv2.ellipse(frame, (int(position[0]), int(position[1])), (9, 3), 0, 0, 360, (0, 0, 255), -1)\n",
    "    cv2.putText(frame, position_label, (int(position[0]) - 50, int(position[1]) + 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Captura cuatro clics del ratón (parte uno)\n",
    "def get_points(event, x, y, flags, param):\n",
    "    points = param[\"points\"]\n",
    "    img = param[\"image\"].copy()\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:  # Botón izquierdo\n",
    "        points.append((x, y))  \n",
    "        \n",
    "        # Dibujar en la imagen\n",
    "        cv2.circle(img, (x, y), 5, (0, 255, 0), -1)\n",
    "        cv2.imshow(param[\"wname\"], img)\n",
    "\n",
    "        # Cuarto puntos, condición de parada\n",
    "        if len(points) == 4:\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Comprueba si la acción se realiza en el lado derecho del campo\n",
    "def is_right_side(court_points):\n",
    "    if len(court_points) < 4:\n",
    "        print(\"Error: court_points length must be 4.\")\n",
    "        return False\n",
    "    return court_points[1][0] < court_points[2][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puntos de referencia de la zona de 3 segundos en el diagrama\n",
    "RIGHT_SIDE_POINTS = [(590, 175), (590, 290), (725, 175), (725, 290)]\n",
    "LEFT_SIDE_POINTS = [(195, 175), (195, 290), (60, 175), (60, 290)]\n",
    "\n",
    "# Función para calcular la matriz de homografía a partir de las esquinas detectadas\n",
    "def calculateHomography(zone_points, is_right_side):\n",
    "    # Puntos del diagrama para la homografía: [A, B, C, D]\n",
    "    diagram_points_right_side = [(1509, 436), (1509, 727), (1854, 436), (1854, 727)]\n",
    "    diagram_points_left_side = [(490, 436), (490, 727), (145, 436), (145, 727)]\n",
    "\n",
    "    if is_right_side:\n",
    "        diagram_points = diagram_points_right_side\n",
    "    else:\n",
    "        diagram_points = diagram_points_left_side\n",
    "\n",
    "    # Matriz de homografía\n",
    "    return transform.estimate_transform('projective', np.array(zone_points), np.array(diagram_points))\n",
    "\n",
    "# Función para dibujar las detecciones en el diagrama\n",
    "def drawDetection(homography_matrix, diagram, player_coords):\n",
    "    diagram_point = homography_matrix(player_coords)\n",
    "    cv2.circle(diagram, (int(diagram_point[0][0]), int(diagram_point[0][1])), 3, (255, 0, 0), -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_detector = YOLO(\"../object_detection/runs/detect/bod_v1/weights/best.pt\")\n",
    "\n",
    "video_path = \"../clips/ClipLF1.mp4\"\n",
    "output_path = \"../output/ClipLF1_output2.mp4\"\n",
    "diagram = cv2.imread('../court_diagrams/fiba_white_court_resized.png')\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"avc1\")\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "court_points = []\n",
    "diagram_points = []\n",
    "\n",
    "first_iteration = True\n",
    "\n",
    "ret, frame = cap.read()  # Leer el primer fotograma\n",
    "if not ret:\n",
    "    print(\"Error al leer el video.\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "# Crea copias de trabajo\n",
    "frametmp = frame.copy()\n",
    "diagramtmp = diagram.copy()\n",
    "\n",
    "#Vista del campo\n",
    "cv2.imshow(\"Vista\", frametmp) \n",
    "params = {\n",
    "    \"points\": court_points,\n",
    "    \"image\": frametmp, \n",
    "    \"wname\": \"Vista\"\n",
    "}\n",
    "cv2.setMouseCallback(\"Vista\", get_points, params)\n",
    "\n",
    "# Selecciona cuatro puntos o cierra ventana\n",
    "cv2.waitKey(0)\n",
    "\n",
    "if is_right_side(court_points):\n",
    "    diagram_points = RIGHT_SIDE_POINTS\n",
    "    print(\"Lado derecho seleccionado.\")\n",
    "else:\n",
    "    diagram_points = LEFT_SIDE_POINTS\n",
    "    print(\"Lado izquierdo seleccionado.\")\n",
    "\n",
    "\n",
    "# Selecciona cuatro puntos o cierra ventana\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Coordenadas campo:\", court_points)\n",
    "print(\"Coordenadas diagrama:\", diagram_points)\n",
    "\n",
    "homography_matrix = transform.estimate_transform(\n",
    "    'projective',\n",
    "    np.array(court_points, dtype=np.float32),\n",
    "    np.array(diagram_points, dtype=np.float32)\n",
    ")\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    if not first_iteration:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "    frametmp = frame.copy()\n",
    "    diagramtmp = diagram.copy()\n",
    "\n",
    "    object_detection_results = object_detector(frame)\n",
    "    # ball_detection_results = ball_detector(frame)\n",
    "    # rim_detection_results = rim_detector(frame)\n",
    "\n",
    "    # Análisis de las detecciones de jugadores\n",
    "    for result in object_detection_results[0].boxes.data.tolist():  # Obtener los resultados como lista\n",
    "        x1, y1, x2, y2, conf, cls = result  # Coordenadas, confianza y clase\n",
    "        cls = int(cls)\n",
    "\n",
    "        # Filtrar solo por las clases deseadas\n",
    "        if object_detector.names[cls] in ['player'] and conf > 0.5:\n",
    "\n",
    "            # Calcular la posición como el punto medio del borde inferior de la bbox\n",
    "            position = (int((x1 + x2) / 2), y2)\n",
    "            position_label = f\"x:{int(position[0])} y:{int(position[1])}\"\n",
    "\n",
    "            label = f\"{object_detector.names[cls]} {conf:.2f}\"\n",
    "\n",
    "            # Dibujar la bbox en el frame\n",
    "            drawBBox(frametmp, x1, y1, x2, y2, label)\n",
    "\n",
    "            # Dibujar la posición en el frame\n",
    "            drawPosition(frametmp, position, position_label)\n",
    "\n",
    "            # Dibujar la detección en el diagrama\n",
    "            drawDetection(homography_matrix, diagramtmp, position)\n",
    "\n",
    "\n",
    "    # Mostrar el frame procesado en pantalla\n",
    "    cv2.imshow('Detecciones', frametmp)\n",
    "    cv2.imshow('Diagrama', diagramtmp)\n",
    "\n",
    "    # Esperar por una tecla: espacio para avanzar, 'q' para salir\n",
    "    key = cv2.waitKey(0) & 0xFF  # Espera indefinidamente hasta que se presione una tecla\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord(' '):  # Espacio para continuar\n",
    "        # Escribir el frame procesado en el video de salida\n",
    "        out.write(frametmp)\n",
    "\n",
    "    first_iteration = False\n",
    "\n",
    "\n",
    "# Liberar recursos\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Video procesado guardado en {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
