{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from mmaction.apis import init_recognizer, inference_recognizer\n",
    "from mmengine.dataset import Compose\n",
    "\n",
    "# Cargar modelos\n",
    "object_detector = YOLO(\"../object_detection/runs/detect/bod_v1/weights/best.pt\")\n",
    "#config_file = \"./models/tsm/5-4-third/tsm_multisubjects.py\"\n",
    "config_file = \"./models/x3d/x3d_s_multisubjects.py\"\n",
    "checkpoint_file = \"./models/x3d/best_45.pth\"\n",
    "model = init_recognizer(config_file, checkpoint_file, device='cuda:0')\n",
    "\n",
    "# Inicializar el tracker\n",
    "tracker = DeepSort(max_age=50, n_init=5, nms_max_overlap=1.0)\n",
    "\n",
    "# Par谩metros\n",
    "clip_len = 8  # Frames por clip\n",
    "MAX_PLAYERS = 10\n",
    "MAX_FRAMES_WITHOUT_DETECTION = 3\n",
    "\n",
    "# Mapeo de IDs del tracker a IDs fijos\n",
    "id_mapping = {}\n",
    "lost_ids = set(range(1, MAX_PLAYERS + 1))\n",
    "active_ids = set()\n",
    "\n",
    "# Diccionario de buffers de frames por jugador\n",
    "player_buffers = {}\n",
    "\n",
    "# Lista para almacenar posiciones de tiros\n",
    "shot_positions = []\n",
    "\n",
    "# Video\n",
    "video_path = \"../clips/ClipLF1.mp4\"\n",
    "output_path = \"../output/ClipLF1_action_output.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "frame_idx = 0  # Contador de frames\n",
    "\n",
    "def create_temp_video(frames, fps=30):\n",
    "    \"\"\"Crea un video temporal a partir de una lista de frames.\"\"\"\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    temp_video_path = os.path.join(temp_dir, 'temp_clip.mp4')\n",
    "    \n",
    "    # Configurar el escritor de video\n",
    "    h, w = frames[0].shape[:2]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    writer = cv2.VideoWriter(temp_video_path, fourcc, fps, (w, h))\n",
    "    \n",
    "    for frame in frames:\n",
    "        writer.write(frame)\n",
    "    writer.release()\n",
    "    \n",
    "    return temp_video_path, temp_dir\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_idx += 1\n",
    "\n",
    "    # Detectar jugadores en el frame actual\n",
    "    detections = []\n",
    "    object_detection_results = object_detector(frame)\n",
    "\n",
    "    for result in object_detection_results[0].boxes.data.tolist():\n",
    "        x1, y1, x2, y2, conf, cls = result\n",
    "        cls = int(cls)\n",
    "\n",
    "        if object_detector.names[cls] == \"player\" and conf > 0.5:\n",
    "            detections.append(([x1, y1, x2 - x1, y2 - y1], conf, cls))\n",
    "\n",
    "    # Actualizar tracker\n",
    "    tracking_results = tracker.update_tracks(detections, frame=frame)\n",
    "    confirmed_tracks = [track for track in tracking_results \n",
    "                       if track.is_confirmed() and track.time_since_update <= MAX_FRAMES_WITHOUT_DETECTION]\n",
    "\n",
    "    for track in confirmed_tracks:\n",
    "        original_id = track.track_id\n",
    "\n",
    "        if original_id in id_mapping:\n",
    "            fixed_id = id_mapping[original_id]\n",
    "        elif lost_ids:\n",
    "            fixed_id = lost_ids.pop()\n",
    "            id_mapping[original_id] = fixed_id\n",
    "            active_ids.add(fixed_id)\n",
    "        else:\n",
    "            continue  # No hay IDs disponibles\n",
    "\n",
    "        x1, y1, x2, y2 = track.to_ltrb()\n",
    "        position = (int((x1 + x2) / 2), y2)\n",
    "\n",
    "        # Extraer y almacenar el recorte del jugador\n",
    "        player_crop = frame[int(y1):int(y2), int(x1):int(x2)]\n",
    "        player_crop = cv2.resize(player_crop, (224, 224))  # Redimensionar a 224x224\n",
    "\n",
    "        if fixed_id not in player_buffers:\n",
    "            player_buffers[fixed_id] = []\n",
    "        player_buffers[fixed_id].append(player_crop)\n",
    "\n",
    "        # Si el buffer tiene suficientes frames, procesar el clip\n",
    "        if len(player_buffers[fixed_id]) == clip_len:\n",
    "            # Crear video temporal\n",
    "            temp_video_path, temp_dir = create_temp_video(player_buffers[fixed_id], fps)\n",
    "            \n",
    "            try:\n",
    "\n",
    "                result = inference_recognizer(model, temp_video_path)\n",
    "                \n",
    "                predicted_class = result.pred_score.argmax().item()\n",
    "\n",
    "                # A帽ade un umbral de confianza \n",
    "                confidence_threshold = 0.80\n",
    "                scores = result.pred_score.tolist()\n",
    "                max_score = max(scores)\n",
    "\n",
    "                if max_score > confidence_threshold:\n",
    "                    predicted_class = scores.index(max_score)\n",
    "                else:\n",
    "                    predicted_class = -1  # Clase \"no acci贸n\"\n",
    "\n",
    "                print(f\"Predicci贸n para ID {fixed_id} en frame {frame_idx}: {predicted_class}\")\n",
    "\n",
    "                if predicted_class in {1, 2}:  # Tiro o Bandeja detectado\n",
    "                    action_name = \"Tiro\" if predicted_class == 1 else \"Bandeja\" if predicted_class == 2 else \"No acci贸n\"\n",
    "                    print(f\" {action_name} detectado en frame {frame_idx}, ID {fixed_id}\")\n",
    "\n",
    "                    # Guardar la posici贸n del tiro\n",
    "                    shot_positions.append((frame_idx, position[0], position[1]))\n",
    "                \n",
    "            finally:\n",
    "                # Limpiar archivos temporales\n",
    "                if os.path.exists(temp_video_path):\n",
    "                    os.remove(temp_video_path)\n",
    "                if os.path.exists(temp_dir):\n",
    "                    os.rmdir(temp_dir)\n",
    "            \n",
    "            # Limpiar buffer (mantener los 煤ltimos frames para solapamiento si es necesario)\n",
    "            player_buffers[fixed_id] = player_buffers[fixed_id][-clip_len//2:]  # Solapamiento del 50%\n",
    "\n",
    "        # Dibujar bounding box y posici贸n del jugador\n",
    "        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n",
    "        cv2.putText(frame, f\"ID: {fixed_id}\", (int(x1), int(y1) - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "    # Actualizar lista de IDs activos\n",
    "    active_now = {id_mapping[track.track_id] for track in confirmed_tracks if track.track_id in id_mapping}\n",
    "    lost_ids.update(active_ids - active_now)\n",
    "    active_ids = active_now\n",
    "\n",
    "    # Guardar frame procesado\n",
    "    out.write(frame)\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Guardar posiciones de tiros detectados\n",
    "np.savetxt(\"../output/shot_positions.csv\", np.array(shot_positions), delimiter=\",\", fmt=\"%d\")\n",
    "\n",
    "# Liberar recursos\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"Posiciones de tiros guardadas en shot_positions.csv\")\n",
    "print(f\"Video procesado guardado en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APROXIMACIN CON YOLOv11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobaci贸n de PyTorch y uso de la GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"Versi贸n de PyTorch: {torch.__version__}\")\n",
    "print(f\"Versi贸n de CUDA en PyTorch: {torch.version.cuda}\")\n",
    "print(f\"驴CUDA est谩 disponible?: {torch.cuda.is_available()}\")\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento de las redes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "results = model.train(data=\"./datasets/bsr_v1/data.yaml\", \n",
    "                      device=0,\n",
    "                      batch=8, \n",
    "                      epochs=100,\n",
    "                      imgsz=1024, \n",
    "                      optimizer='SGD', \n",
    "                      lr0=0.01, \n",
    "                      lrf=0.1, \n",
    "                      weight_decay=0.0005, \n",
    "                      task=\"detect\",\n",
    "                      patience=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconocimiento de tiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getColor(class_name):\n",
    "    switch = {\n",
    "        'player': (255, 0, 0),       # Azul\n",
    "        'basketball': (0, 165, 255), # Naranja\n",
    "        'rim': (0, 0, 255),          # Rojo\n",
    "        'made-shot': (0, 255, 0)     # Verde\n",
    "    }\n",
    "    return switch.get(class_name, (0, 0, 0)) \n",
    "\n",
    "def drawBBox(frame, x1, y1, x2, y2, label, class_name):\n",
    "    color = getColor(class_name)\n",
    "    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "    cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "def drawPosition(frame, position, position_label):\n",
    "    cv2.ellipse(frame, (int(position[0]), int(position[1])), (9, 3), 0, 0, 360, (0, 0, 255), -1)\n",
    "    cv2.putText(frame, position_label, (int(position[0]) - 50, int(position[1]) + 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "shoot_detector = YOLO(\"./runs/detect/bsr_v2/weights/best.pt\")\n",
    "object_detector = YOLO(\"../object_detection/runs/detect/bod_v1/weights/best.pt\")\n",
    "\n",
    "video_path = \"../clips/ClipS2.mp4\"\n",
    "output_path = \"../output/ClipS2_action_output.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"avc1\")\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "\n",
    "csv_lines = []\n",
    "rim_logged = False\n",
    "\n",
    "frame_idx = 0  # Contador de frames\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    shoot_detection_results = shoot_detector(frame)\n",
    "    object_detection_results = object_detector(frame)\n",
    "\n",
    "    frame_idx += 1\n",
    "    \n",
    "    # SHOOT DETECTIONS\n",
    "    for result in shoot_detection_results[0].boxes.data.tolist():\n",
    "        x1, y1, x2, y2, conf, cls = result\n",
    "        cls = int(cls)\n",
    "\n",
    "        if shoot_detector.names[cls] == 'shoot' and conf > 0.3:\n",
    "            position = (int((x1 + x2) / 2), int(y2))\n",
    "            label = f\"{shoot_detector.names[cls]} {conf:.2f}\"\n",
    "\n",
    "            drawBBox(frame, x1, y1, x2, y2, label, 'shoot')\n",
    "            drawPosition(frame, position, f\"x:{position[0]} y:{position[1]}\")\n",
    "\n",
    "            csv_lines.append(f\"s,{frame_idx},{position[0]},{position[1]}\")\n",
    "\n",
    "    # OBJECT DETECTIONS\n",
    "    for result in object_detection_results[0].boxes.data.tolist():\n",
    "        x1, y1, x2, y2, conf, cls = result\n",
    "        cls = int(cls)\n",
    "        label_name = object_detector.names[cls]\n",
    "\n",
    "        if label_name in ['player', 'basketball', 'rim'] and conf > 0.7:\n",
    "            drawBBox(frame, x1, y1, x2, y2, f\"{label_name} {conf:.2f}\", label_name)\n",
    "\n",
    "            # Guardar posici贸n del rim una sola vez\n",
    "            if label_name == 'rim' and not rim_logged:\n",
    "                x_rim = int((x1 + x2) / 2)\n",
    "                y_rim = int((y1 + y2) / 2)\n",
    "                csv_lines.insert(0, f\"r,0,{x_rim},{y_rim}\")  # Primera l铆nea\n",
    "                rim_logged = True\n",
    "\n",
    "        if label_name == 'made-shot' and conf > 0.3:\n",
    "            position = (int((x1 + x2) / 2), int((y1 + y2) / 2))\n",
    "            drawBBox(frame, x1, y1, x2, y2, f\"{label_name} {conf:.2f}\", label_name)\n",
    "            csv_lines.append(f\"m,{frame_idx},{position[0]},{position[1]}\")\n",
    "\n",
    "\n",
    "    # Mostrar el frame procesado en pantalla\n",
    "    cv2.imshow('Resultados', frame)\n",
    "\n",
    "\n",
    "    \"\"\" # Esperar por una tecla: espacio para avanzar, 'q' para salir\n",
    "    key = cv2.waitKey(0) & 0xFF  # Espera indefinidamente hasta que se presione una tecla\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord(' '):  # Espacio para continuar\n",
    "        # Escribir el frame procesado en el video de salida\n",
    "        out.write(frame) \"\"\"\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    \n",
    "\n",
    "# Guardar CSV con las detecciones\n",
    "with open(\"../output/shot_positions.csv\", \"w\") as f:\n",
    "    for line in csv_lines:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "# Liberar recursos\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Video procesado guardado en {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estimaci贸n de pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "shoot_detector = YOLO(\"./runs/detect/bsr_v2/weights/best.pt\")\n",
    "object_detector = YOLO(\"../object_detection/runs/detect/bod_v1/weights/best.pt\")\n",
    "pose_model = YOLO(\"yolo11n-pose.pt\")\n",
    "\n",
    "video_path = \"../clips/ClipS4.mp4\"\n",
    "output_path = \"../output/ClipS4_action_pose_output.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"avc1\")\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "frame_idx = 0\n",
    "csv_lines = []\n",
    "rim_logged = False\n",
    "\n",
    "# Keypoints visibles: ojos, hombros, codos, mu帽ecas, caderas\n",
    "visible_kps = [1, 2, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "# Pares de 铆ndices para dibujar l铆neas anat贸micas\n",
    "connections = [\n",
    "    (5, 7), (7, 9),  # Brazo izquierdo\n",
    "    (6, 8), (8,10),  # Brazo derecho\n",
    "    (5, 6),          # Hombros\n",
    "    (11, 12),        # Caderas\n",
    "    (5,11), (6,12)   # Hombro a cadera\n",
    "]\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_idx += 1\n",
    "    shoot_results = shoot_detector(frame)\n",
    "    object_results = object_detector(frame)\n",
    "\n",
    "    # ---- SHOOT DETECTIONS ----\n",
    "    for result in shoot_results[0].boxes.data.tolist():\n",
    "        x1, y1, x2, y2, conf, cls = result\n",
    "        cls = int(cls)\n",
    "        if shoot_detector.names[cls] == 'shoot' and conf > 0.3:\n",
    "            position = (int((x1 + x2) / 2), int(y2))\n",
    "            drawBBox(frame, x1, y1, x2, y2, f\"shoot {conf:.2f}\", 'shoot')\n",
    "            drawPosition(frame, position, f\"x:{position[0]} y:{position[1]}\")\n",
    "            csv_lines.append(f\"s,{frame_idx},{position[0]},{position[1]}\")\n",
    "\n",
    "    # ---- OBJECT DETECTIONS & POSE ----\n",
    "    for result in object_results[0].boxes.data.tolist():\n",
    "        x1, y1, x2, y2, conf, cls = result\n",
    "        cls = int(cls)\n",
    "        label_name = object_detector.names[cls]\n",
    "\n",
    "        if label_name in ['player', 'basketball', 'rim', 'made-shot'] and conf > 0.5:\n",
    "            drawBBox(frame, x1, y1, x2, y2, f\"{label_name} {conf:.2f}\", label_name)\n",
    "\n",
    "            # Registrar RIM\n",
    "            if label_name == 'rim' and not rim_logged:\n",
    "                x_rim = int((x1 + x2) / 2)\n",
    "                y_rim = int((y1 + y2) / 2)\n",
    "                csv_lines.insert(0, f\"r,0,{x_rim},{y_rim}\")\n",
    "                rim_logged = True\n",
    "\n",
    "            # Registrar made-shot\n",
    "            if label_name == 'made-shot':\n",
    "                pos = (int((x1 + x2) / 2), int((y1 + y2) / 2))\n",
    "                csv_lines.append(f\"m,{frame_idx},{pos[0]},{pos[1]}\")\n",
    "\n",
    "            # Pose para players\n",
    "            if label_name == 'player':\n",
    "                # --- Recortar bbox del jugador ---\n",
    "                x1i, y1i, x2i, y2i = map(int, [x1, y1, x2, y2])\n",
    "                cropped = frame[y1i:y2i, x1i:x2i].copy()\n",
    "\n",
    "                # Evitar errores por crops vac铆os\n",
    "                if cropped.size == 0 or cropped.shape[0] < 10 or cropped.shape[1] < 10:\n",
    "                    continue\n",
    "\n",
    "                pose_results = pose_model(cropped)\n",
    "\n",
    "                # Procesar keypoints\n",
    "                if hasattr(pose_results[0], \"keypoints\"):\n",
    "                    for det in pose_results[0].keypoints.data.tolist():\n",
    "                        for idx, kp in enumerate(det):\n",
    "                            if idx not in visible_kps:\n",
    "                                continue\n",
    "                            px, py, kp_conf = kp\n",
    "                            if kp_conf > 0.5:\n",
    "                                # Convertir a coordenadas del frame original\n",
    "                                global_x = int(px + x1i)\n",
    "                                global_y = int(py + y1i)\n",
    "                                cv2.circle(frame, (global_x, global_y), 3, (0, 255, 0), -1)\n",
    "\n",
    "\n",
    "    # Mostrar frame\n",
    "    cv2.imshow('Resultados', frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Guardar CSV\n",
    "with open(\"../output/shot_positions.csv\", \"w\") as f:\n",
    "    for line in csv_lines:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"Video procesado guardado en {output_path}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tftv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
